# LLM-for-code-intelligence
Fine Tuning Large Language Models for Code Intelligence - Msc Project

## Todo List 19/06 - 25/06
- [ ] Document Current Challenges, Progress and Next Steps to progress\README.md
- [x] Identify Relevant Literature
- [ ] Read Identified Literature and summarise to lit-rev\README.md (Ongoing)
- [ ] Identify Relevant Datasets
- [ ] Document Identified Datasets to lit-rev\README.md
- [ ] Identify Relevant Evaluation Metrics
- [ ] Document Identified Evaluation Metrics to lit-rev\README.md
- [ ] Setup the code generation environment
- [ ] Document the code generation environment setup
- [ ] Setup the functional evaluation environment
- [ ] Document the functional evaluation environment setup
- [ ] Setup the similarity evaluation environment
- [ ] Document the similarity evaluation environment setup
- [ ] Setup the Full Fine Tuning environment
- [ ] Document the Full Fine Tuning environment setup
- [ ] Setup the Parameter Efficient Fine Tuning environment
- [ ] Document the Parameter Efficient Fine Tuning environment setup
- [ ] Setup the Knowledge Distillation environment
- [ ] Document the Knowledge Distillation environment setup

## Todo List 26/06 - 02/07
- [ ] Try to expirment with the Learning Rate
- [ ] Try to expirment with the Number of Layers to Freeze
- [ ] Try to expirment with using a sample of the dataset processed and downloaded from the cloud
- [ ] correlation between evaluation metrics and the number of fine-tuning steps
- [ ] Smimlar Setup for the Parameter Efficient Fine Tuning and Full Fine Tuning
- [ ] Documnetaion of progress and next steps




## Fine-tuning CodeGen on CodexGLUE

Colab: <a href="https://colab.research.google.com/drive/1B_cfCkliI-UuNemmgMmXqxgjnDLslAq1?usp=sharing"><img src="https://colab.research.google.com/assets/colab-badge.svg" height=20></a>  

Huggingface: <a href="https://huggingface.co/ammarnasr/codegen-350M-multi-ft-on-code-x-glue-tc"><img src="https://huggingface.co/datasets/huggingface/badges/raw/main/share-to-community-sm-dark.svg"></a>

Weights & Biases: <a href="https://wandb.ai/ammarnasr/codegen_ft_on_codexglue?workspace=user-ammarnasr"><img src="https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"></a>


## Evaluation on HumanEval

### CodeGen with 350M parameters - No fine-tuning

Colab: <a href="https://colab.research.google.com/drive/17cnKw8n2ELFLdu9i7zqi5mb99QdZdaax?usp=sharing"><img src="https://colab.research.google.com/assets/colab-badge.svg" height=20></a>

<!-- TODO: add Hugging Face and WandB -->

Huggingface: TODO

Weights & Biases: TODO

### CodeGen with 350M parameters - Fine-tuned on CodexGLUE
<!-- TODO: add Colab, HuggingFace and WandB -->

Colab: TODO

Huggingface: TODO

Weights & Biases: TODO

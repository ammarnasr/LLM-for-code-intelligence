# LLM-for-code-intelligence
Fine Tuning Large Language Models for Code Intelligence - Msc Project

## Todo List 19/06 - 25/06
- [x] Document Current Challenges, Progress and Next Steps to progress\README.md
- [x] Identify Relevant Literature
- [x] Read Identified Literature and summarise to lit-rev\README.md (Ongoing)
- [x] Identify Relevant Datasets
- [x] Document Identified Datasets to lit-rev\README.md
- [x] Identify Relevant Evaluation Metrics
- [x] Document Identified Evaluation Metrics to lit-rev\README.md
- [x] Setup the code generation environment
- [x] Document the code generation environment setup
- [x] Setup the functional evaluation environment
- [x] Document the functional evaluation environment setup
- [x] Setup the similarity evaluation environment
- [x] Document the similarity evaluation environment setup
- [x] Setup the Full Fine Tuning environment
- [x] Document the Full Fine Tuning environment setup
- [x] Setup the Parameter Efficient Fine Tuning environment
- [x] Document the Parameter Efficient Fine Tuning environment setup
- [ ] Setup the Knowledge Distillation environment
- [ ] Document the Knowledge Distillation environment setup

## Todo List 26/06 - 02/07
- [x] Try to expirment with the Learning Rate
- [ ] Try to expirment with the Number of Layers to Freeze
- [x] Try to expirment with using a sample of the dataset processed and downloaded from the cloud
- [x] correlation between evaluation metrics and the number of fine-tuning steps
- [x] Smimlar Setup for the Parameter Efficient Fine Tuning and Full Fine Tuning
- [ ] Documnetaion of progress and next steps


## Colab Notebooks
Code-LLM-finetuning-V2.ipynb: <a href="https://colab.research.google.com/drive/1BuRz-HBFCjxpmJfMg7QedbfNDXPl7Kap?usp=sharing"><img src="assets/colab-badge.svg" height=10></a>  [ammar nasr]

Code-LLM-finetuning-LoRa-V2.ipynb <a href="https://colab.research.google.com/drive/1iWzsUeih_ObBJwmOkuD5D9Wm72eiRbQV?usp=sharing"><img src="assets/colab-badge.svg" height=10></a>  [rdin uni]


Code-LLM-Perplexity.ipynb <a href="https://colab.research.google.com/drive/105aYjjovxfWKRifK5uzDfoQ2ZrTykoa4?usp=sharing"><img src="assets/colab-badge.svg" height=10></a>  [brilliant]


Code-LLM-Generation-Python.ipynb <a href="https://colab.research.google.com/drive/1gQ2GOwz40tNqF8UDakGsiZngJVt21DHI?usp=sharing"><img src="assets/colab-badge.svg" height=10></a>  [chat gpt]


Code-LLM-Generation-Java.ipynb <a href="https://colab.research.google.com/drive/13ocCjQwO0-hwkEt1xWNzRVFkfzMBn459?usp=sharing"><img src="assets/colab-badge.svg" height=10></a>  [brilliant premuim]

Code-LLM-Ablations.ipynb <a href="https://colab.research.google.com/drive/10ZIvvJml4cDMPVBPH_4QlLrU091XdGDA?usp=sharing"><img src="assets/colab-badge.svg" height=10></a>  [lora llm]






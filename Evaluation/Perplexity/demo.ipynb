{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:15<00:00, 63.39it/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "language = \"Java\"\n",
    "license = \"apache-2.0\"\n",
    "size = 1000\n",
    "\n",
    "\n",
    "ds = load_dataset(\"codeparrot/github-code\", languages=[language], licenses=[license], streaming=True, split=\"train\")\n",
    "ds = ds.shuffle(buffer_size=size)\n",
    "ds = ds.take(size)\n",
    "evaluation_dataset = []\n",
    "\n",
    "for item in tqdm(ds, total=size):\n",
    "    evaluation_dataset.append(item['code'])\n",
    "\n",
    "\n",
    "eval_data_name = f\"evaluation_data_{language}_{license}_{size}.pkl\"\n",
    "\n",
    "with open(eval_data_name, 'wb') as f:\n",
    "    pickle.dump(evaluation_dataset, f)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:20<00:00, 12.39it/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "language = \"Python\"\n",
    "license = \"apache-2.0\"\n",
    "size = 1000\n",
    "\n",
    "\n",
    "ds = load_dataset(\"codeparrot/github-code\", languages=[language], licenses=[license], streaming=True, split=\"train\")\n",
    "ds = ds.shuffle(buffer_size=size)\n",
    "ds = ds.take(size)\n",
    "evaluation_dataset = []\n",
    "\n",
    "for item in tqdm(ds, total=size):\n",
    "    evaluation_dataset.append(item['code'])\n",
    "\n",
    "\n",
    "eval_data_name = f\"evaluation_data_{language}_{license}_{size}.pkl\"\n",
    "\n",
    "with open(eval_data_name, 'wb') as f:\n",
    "    pickle.dump(evaluation_dataset, f)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelWithLMHead\n",
    "import torch\n",
    "\n",
    "def get_perplexity(model, tokenizer, input, stride=512, device='cuda'):\n",
    "    encodings = tokenizer(input, return_tensors=\"pt\")\n",
    "\n",
    "    model.to(device)\n",
    "    encodings.to(device)\n",
    "    \n",
    "    max_length = model.config.n_positions\n",
    "\n",
    "    seq_len = encodings.input_ids.size(1)\n",
    "\n",
    "    nlls = []\n",
    "    prev_end_loc = 0\n",
    "    for begin_loc in tqdm(range(0, seq_len, stride)):\n",
    "        end_loc = min(begin_loc + max_length, seq_len)\n",
    "        trg_len = end_loc - prev_end_loc  # may be different from stride on last loop\n",
    "        input_ids = encodings.input_ids[:, begin_loc:end_loc].to(device)\n",
    "        target_ids = input_ids.clone()\n",
    "        target_ids[:, :-trg_len] = -100\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids, labels=target_ids)\n",
    "            neg_log_likelihood = outputs.loss\n",
    "\n",
    "        nlls.append(neg_log_likelihood)\n",
    "\n",
    "        prev_end_loc = end_loc\n",
    "        if end_loc == seq_len:\n",
    "            break\n",
    "\n",
    "    ppl = torch.exp(torch.stack(nlls).mean())\n",
    "\n",
    "    return ppl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Edin\\anaconda3\\envs\\amazon\\lib\\site-packages\\transformers\\models\\auto\\modeling_auto.py:1295: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_name = \"Salesforce/codegen-350M-mono\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelWithLMHead.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "sample = evaluation_dataset[0]\n",
    "\n",
    "ppl = get_perplexity(model, tokenizer, evaluation_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.0420, device='cuda:0')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amazon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import code_generation\n",
    "prompt_file_names = [\n",
    "    \"humaneval_java.jsonl\",\n",
    "]\n",
    "using_Lora = False\n",
    "model_name = \"Salesforce/codegen-350M-mono\"\n",
    "tokenizer_name = \"Salesforce/codegen-350M-mono\"\n",
    "generation_strategy = \"ammarnasr/pass_at_10_gen_config\"\n",
    "gen_name = generation_strategy.split('/')[-1]\n",
    "batch_size = 20\n",
    "for prompt_file_name in prompt_file_names:\n",
    "    model_name_short = model_name.split(\"/\")[-1]\n",
    "    model_name_short = model_name_short.replace(\"-\", \"_\")\n",
    "    prompt_file_name_short = prompt_file_name.split(\"/\")[-1]\n",
    "    prompt_file_name_short = prompt_file_name_short.split(\".\")[0]\n",
    "    output_file_name = f\"runs/{model_name_short}_{prompt_file_name_short}_{gen_name}_x.jsonl\"\n",
    "\n",
    "    wandb_project_name = f\"{model_name_short}_{prompt_file_name_short}\"\n",
    "\n",
    "    args_dict = {\n",
    "        \"prompts_file_name\": prompt_file_name,\n",
    "        \"model_name\": model_name,\n",
    "        \"tokenizer_name\": tokenizer_name,\n",
    "        \"generation_strategy\": generation_strategy,\n",
    "        \"output_file_name\": output_file_name,\n",
    "        \"wandb_project_name\": wandb_project_name,\n",
    "        \"batch_size\": batch_size,\n",
    "    }\n",
    "    print(args_dict)\n",
    "\n",
    "    code_generation.main(args_dict, with_peft=using_Lora)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonlines as jsonl\n",
    "import os\n",
    "import json\n",
    "\n",
    "prompt= '''\n",
    "def intersection(interval1: Tuple[int, int], interval2: Tuple[int, int]) -> str:\n",
    "    \"\"\"\n",
    "    Determines whether the intersection of two closed intervals results in a prime-length interval.\n",
    "    \n",
    "    Args:\n",
    "        interval1 (Tuple[int, int]): The first closed interval as a tuple (start, end).\n",
    "        interval2 (Tuple[int, int]): The second closed interval as a tuple (start, end).\n",
    "        \n",
    "    Returns:\n",
    "        str: Returns 'YES' if the length of the intersection is a prime number, 'NO' otherwise.\n",
    "            If the two intervals don't intersect, also returns 'NO'.\n",
    "    \"\"\"\n",
    "'''\n",
    "tests = '''\n",
    "def check(candidate):\n",
    "    assert candidate((1, 2), (2, 3)) == 'NO'\n",
    "    assert candidate((-1, 1), (0, 4)) == 'NO'\n",
    "    assert candidate((-3, -1), (-5, 5)) == 'YES'\n",
    "    assert candidate((-2, 2), (-4, 0)) == 'YES'\n",
    "    assert candidate((-11, 2), (-1, -1)) == 'NO'\n",
    "    assert candidate((1, 2), (3, 5)) == 'NO'\n",
    "    assert candidate((1, 2), (1, 2)) == 'NO'\n",
    "    assert candidate((-2, -2), (-3, -2)) == 'NO'\n",
    "\n",
    "def test_check():\n",
    "    check(intersection)\n",
    "\n",
    "test_check()\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "#File name \n",
    "file_name = \"custome_py.jsonl\"\n",
    "\n",
    "#Open file\n",
    "with jsonl.open(file_name) as reader:\n",
    "    for obj in reader:\n",
    "        print(obj)\n",
    "        break\n",
    "\n",
    "#Update file\n",
    "obj['prompt'] = prompt\n",
    "obj['tests'] = tests\n",
    "obj['name'] = \"my_prompt\"\n",
    "\n",
    "#Write to file\n",
    "with jsonl.open(file_name, mode='w') as writer:\n",
    "    writer.write(obj)\n",
    "\n",
    "dir_name = \"custome_runs\"\n",
    "if not os.path.exists(dir_name):\n",
    "    os.mkdir(dir_name)\n",
    "\n",
    "\n",
    "#Open file\n",
    "with jsonl.open(file_name) as reader:\n",
    "    for obj in reader:\n",
    "        # print(obj['prompt'])\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_results(exp_name):\n",
    "    convert_to_pre_eval(exp_name)\n",
    "    run_evaluation(exp_name)\n",
    "def convert_to_pre_eval(exp_name):\n",
    "    sf = f'custome_runs/{exp_name}'\n",
    "    td = f'custome_runs/tgt/{exp_name.replace(\"-\", \"\")}'\n",
    "    !python convert_to_pre_eval.py --source_file $sf --target_dir $td\n",
    "    print(f'Converted {sf} to {td}')\n",
    "def run_evaluation(exp_name):\n",
    "    sf = f'custome_runs/{exp_name}'\n",
    "    td = f'custome_runs/tgt/{exp_name.replace(\"-\", \"\")}'\n",
    "    eval_cmd = f\"podman run --rm --network none -v ./{td}:/{td}:rw multipl-e-eval --dir /{td} --output-dir /{td} --recursive\"\n",
    "    !{eval_cmd}\n",
    "\n",
    "\n",
    "def get_results(results_file):\n",
    "    with open(results_file, 'r') as f:\n",
    "        results = json.load(f)\n",
    "    all_results = []\n",
    "    for r in results['results']:\n",
    "        # print(r['status'])\n",
    "        all_results.append(r['status'])\n",
    "    return all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import code_generation\n",
    "prompt_file_names = [\n",
    "    \"custome_py.jsonl\",\n",
    "]\n",
    "k = '100'\n",
    "using_Lora = False\n",
    "model_name = \"Salesforce/codegen-350M-mono\"\n",
    "tokenizer_name = \"Salesforce/codegen-350M-mono\"\n",
    "generation_strategy = f\"ammarnasr/pass_at_{k}_gen_config\"\n",
    "gen_name = generation_strategy.split('/')[-1]\n",
    "batch_size = 5\n",
    "for prompt_file_name in prompt_file_names:\n",
    "    model_name_short = model_name.split(\"/\")[-1]\n",
    "    model_name_short = model_name_short.replace(\"-\", \"_\")\n",
    "    prompt_file_name_short = prompt_file_name.split(\"/\")[-1]\n",
    "    prompt_file_name_short = prompt_file_name_short.split(\".\")[0]\n",
    "    output_file_name = f\"custome_runs/{model_name_short}_{prompt_file_name_short}_{gen_name}.jsonl\"\n",
    "\n",
    "    wandb_project_name = f\"{model_name_short}_{prompt_file_name_short}\"\n",
    "\n",
    "    args_dict = {\n",
    "        \"prompts_file_name\": prompt_file_name,\n",
    "        \"model_name\": model_name,\n",
    "        \"tokenizer_name\": tokenizer_name,\n",
    "        \"generation_strategy\": generation_strategy,\n",
    "        \"output_file_name\": output_file_name,\n",
    "        \"wandb_project_name\": wandb_project_name,\n",
    "        \"batch_size\": batch_size,\n",
    "    }\n",
    "    print(args_dict)\n",
    "\n",
    "    code_generation.main(args_dict, with_peft=using_Lora)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "exp_name = f'codegen_350M_mono_custome_py_pass_at_{k}_gen_config.jsonl'\n",
    "results_file = f'custome_runs/tgt/codegen_350M_mono_custome_py_pass_at_{k}_gen_config.jsonl/my_prompt.results.json'\n",
    "\n",
    "generate_results(exp_name)\n",
    "all_results = get_results(results_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_results = np.array(all_results)\n",
    "print(np.unique(all_results, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amazon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
